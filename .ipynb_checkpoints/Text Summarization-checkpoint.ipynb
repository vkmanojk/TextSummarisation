{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.nlp.stemmers import Stemmer\n",
    "from sumy.utils import get_stop_words\n",
    "\n",
    "from sumy.summarizers.lex_rank import LexRankSummarizer \n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "from sumy.summarizers.edmundson import EdmundsonSummarizer\n",
    "from sumy.summarizers.sum_basic import SumBasicSummarizer\n",
    "from sumy.summarizers.kl import KLSummarizer\n",
    "from sumy.summarizers.reduction import ReductionSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n",
      "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
      "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "Id                                                                 \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
       "\n",
       "    HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "Id                                                                     \n",
       "1                        1      5  1303862400  Good Quality Dog Food   \n",
       "2                        0      1  1346976000      Not as Advertised   \n",
       "\n",
       "                                                 Text  \n",
       "Id                                                     \n",
       "1   I have bought several of the Vitality canned d...  \n",
       "2   Product arrived labeled as Jumbo Salted Peanut...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv', index_col = 'Id')[:5]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "# df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>Not as Advertised</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>Cough Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>Great taffy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review                Summary\n",
       "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
       "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
       "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
       "4  Great taffy at a great price.  There was a wid...            Great taffy"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.DataFrame({\n",
    "    'Review':df['Text'].values, \n",
    "    'Summary':df['Summary'].values})\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there had\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    text = text.lower().split()\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    text = \" \".join(new_text)\n",
    "    \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'\\.+', \".\", text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned summaries\n",
      "Cleaned Reviews\n"
     ]
    }
   ],
   "source": [
    "clean_summaries = []\n",
    "for summary in reviews['Summary']:\n",
    "    clean_summaries.append(clean_text(summary, remove_stopwords=False))\n",
    "print(\"Cleaned summaries\")\n",
    "\n",
    "clean_texts = []\n",
    "for text in reviews['Review']:\n",
    "    clean_texts.append(clean_text(text))\n",
    "print(\"Cleaned Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Review # 1\n",
      "bought several vitality canned dog food products found good quality. product looks like stew processed meat smells better. labrador finicky appreciates product better most.\n",
      "Summary\n",
      "good quality dog food\n",
      "\n",
      "Clean Review # 2\n",
      "product arrived labeled jumbo salted peanuts.the peanuts actually small sized unsalted. sure error vendor intended represent product jumbo .\n",
      "Summary\n",
      "not as advertised\n",
      "\n",
      "Clean Review # 3\n",
      "confection around centuries. light pillowy citrus gelatin nuts case filberts. cut tiny squares liberally coated powdered sugar. tiny mouthful heaven. chewy flavorful. highly recommend yummy treat. familiar story c.s. lewis lion witch wardrobe treat seduces edmund selling brother sisters witch.\n",
      "Summary\n",
      " delight  says it all\n",
      "\n",
      "Clean Review # 4\n",
      "looking secret ingredient robitussin believe found it. got addition root beer extract ordered good made cherry soda. flavor medicinal.\n",
      "Summary\n",
      "cough medicine\n",
      "\n",
      "Clean Review # 5\n",
      "great taffy great price. wide assortment yummy taffy. delivery quick. taffy lover deal.\n",
      "Summary\n",
      "great taffy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Clean Review #\",i+1)\n",
    "    print(clean_texts[i])\n",
    "    print(\"Summary\")\n",
    "    print(clean_summaries[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData = reviews.iloc[:int(len(reviews) * 0.8)]\n",
    "# testData = reviews.iloc[int(len(reviews) * 0.8):]\n",
    "\n",
    "# trainX = trainData['Review'].values\n",
    "# trainy = trainData['Summary'].values\n",
    "# testX = testData['Review'].values\n",
    "# testy = testData['Summary'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'english'\n",
    "sentence_count = 1\n",
    "sw = stopwords.words('english') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(X, Y):\n",
    "    X_list = word_tokenize(X)  \n",
    "    Y_list = word_tokenize(Y)  \n",
    "    l1 =[]\n",
    "    l2 =[] \n",
    "    X_set = {w for w in X_list if not w in sw}  \n",
    "    Y_set = {w for w in Y_list if not w in sw} \n",
    "    rvector = X_set.union(Y_set)  \n",
    "    for w in rvector: \n",
    "        if w in X_set: \n",
    "            l1.append(1)  \n",
    "        else: \n",
    "            l1.append(0) \n",
    "        if w in Y_set: \n",
    "            l2.append(1) \n",
    "        else: \n",
    "            l2.append(0)\n",
    "    c = 0\n",
    "    for i in range(len(rvector)): \n",
    "            c += l1[i] * l2[i] \n",
    "    temp = float((sum(l1)*sum(l2))**0.5)\n",
    "    if float((sum(l1)*sum(l2))**0.5) == 0:\n",
    "        temp = -float(\"inf\")\n",
    "    cosine = c / temp\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LexRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer1 = LexRankSummarizer(Stemmer(language))\n",
    "summarizer1.stopwords = get_stop_words(language)\n",
    "lexRankSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser(clean_texts[i], Tokenizer(language))\n",
    "    lexRankSummary.append(summarizer1(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexRankCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in lexRankSummary[i]:\n",
    "        lexRankCosine += cosine(clean_summaries[i], str(sentence))\n",
    "lexRankCosine = lexRankCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Luhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer2 = LuhnSummarizer(Stemmer(language))\n",
    "summarizer2.stop_words = get_stop_words(language)\n",
    "luhnSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    luhnSummary.append(summarizer2(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "luhnCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in luhnSummary[i]:\n",
    "        luhnCosine += cosine(clean_summaries[i], str(sentence))\n",
    "luhnCosine = luhnCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sumy/summarizers/lsa.py:76: UserWarning: Number of words (1) is lower than number of sentences (2). LSA algorithm may not work properly.\n",
      "  warn(message % (words_count, sentences_count))\n"
     ]
    }
   ],
   "source": [
    "summarizer3 = LsaSummarizer(Stemmer(language))\n",
    "summarizer3.stop_words = get_stop_words(language)\n",
    "lsaSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    lsaSummary.append(summarizer3(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsaCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in lsaSummary[i]:\n",
    "        lsaCosine += cosine(clean_summaries[i], str(sentence))\n",
    "lsaCosine = lsaCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer4 = TextRankSummarizer(Stemmer(language))\n",
    "summarizer4.stop_words = get_stop_words(language)\n",
    "textRankSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    textRankSummary.append(summarizer4(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "textRankCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in textRankSummary[i]:\n",
    "        textRankCosine += cosine(clean_summaries[i], str(sentence))\n",
    "textRankCosine = textRankCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edmundson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer5 = EdmundsonSummarizer(Stemmer(language))\n",
    "summarizer5.stop_words = get_stop_words(language)\n",
    "edmundsonSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    summarizer5.bonus_words = ['good'] + clean_texts[i].split()\n",
    "    summarizer5.stigma_words = ['bad', 'worst']\n",
    "    summarizer5.null_words = ['zdfgthdvndadv']\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    edmundsonSummary.append(summarizer5(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "edmundsonCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in edmundsonSummary[i]:\n",
    "        edmundsonCosine += cosine(clean_summaries[i], str(sentence))\n",
    "edmundsonCosine = edmundsonCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SumBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer6 = SumBasicSummarizer(Stemmer(language))\n",
    "summarizer6.stop_words = get_stop_words(language)\n",
    "sumBasicSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    sumBasicSummary.append(summarizer6(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumBasicCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in sumBasicSummary[i]:\n",
    "        sumBasicCosine += cosine(clean_summaries[i], str(sentence))\n",
    "sumBasicCosine = sumBasicCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL Summariser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer7 = KLSummarizer(Stemmer(language))\n",
    "summarizer7.stop_words = get_stop_words(language)\n",
    "klSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    klSummary.append(summarizer7(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "klCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in klSummary[i]:\n",
    "        klCosine += cosine(clean_summaries[i], str(sentence))\n",
    "klCosine = klCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer8 = KLSummarizer(Stemmer(language))\n",
    "summarizer8.stop_words = get_stop_words(language)\n",
    "reductionSummary = []\n",
    "for i in range(len(clean_texts)):\n",
    "    parser = PlaintextParser.from_string(clean_texts[i], Tokenizer(language))\n",
    "    reductionSummary.append(summarizer8(parser.document, sentence_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductionCosine = 0\n",
    "for i in range(len(clean_summaries)):\n",
    "    for sentence in reductionSummary[i]:\n",
    "        reductionCosine += cosine(clean_summaries[i], str(sentence))\n",
    "reductionCosine = reductionCosine/len(clean_summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between golden summary & LexRank   : 0.159\n",
      "Similarity between golden summary & Luhn      : 0.142\n",
      "Similarity between golden summary & LSA       : 0.116\n",
      "Similarity between golden summary & TextRank  : 0.131\n",
      "Similarity between golden summary & Edmundson : 0.122\n",
      "Similarity between golden summary & sumBasic  : 0.145\n",
      "Similarity between golden summary & KL        : 0.118\n",
      "Similarity between golden summary & Reduction : 0.118\n"
     ]
    }
   ],
   "source": [
    "print('Similarity between golden summary & LexRank   : %.3f' % lexRankCosine)\n",
    "print('Similarity between golden summary & Luhn      : %.3f' % luhnCosine)\n",
    "print('Similarity between golden summary & LSA       : %.3f' % lsaCosine)\n",
    "print('Similarity between golden summary & TextRank  : %.3f' % textRankCosine)\n",
    "print('Similarity between golden summary & Edmundson : %.3f' % edmundsonCosine)\n",
    "print('Similarity between golden summary & sumBasic  : %.3f' % sumBasicCosine)\n",
    "print('Similarity between golden summary & KL        : %.3f' % klCosine)\n",
    "print('Similarity between golden summary & Reduction : %.3f' % reductionCosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
